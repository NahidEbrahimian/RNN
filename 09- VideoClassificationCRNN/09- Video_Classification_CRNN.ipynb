{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gTdsiHXD79J6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc1b48cb-1c46-4b71-801b-12a91498a3f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/video_classification_rnn\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "\n",
        "%cd /content/drive/MyDrive/video_classification_rnn\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, SimpleRNN, GRU, LSTM, Dense, Flatten, TimeDistributed\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from models import RNN_model, GRU_model, LSTM_model\n",
        "from load_video import load_video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1EHFf5uq912f"
      },
      "outputs": [],
      "source": [
        "# Parameters setting\n",
        "\n",
        "frame_width = 112\n",
        "frame_height = 112\n",
        "\n",
        "batch_size = 1\n",
        "epochs = 10\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/dataset/joon_del\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directories\n",
        "\n",
        "if not os.path.exists(\"weights\"):\n",
        "    os.makedirs(\"weights\")"
      ],
      "metadata": {
        "id": "nRBVqvMwk8JH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNRiIBDroa3M"
      },
      "source": [
        "### Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count maximum number of frames in all videos\n",
        "\n",
        "num_classes = os.listdir(dataset_path)\n",
        "count_frames = []\n",
        "\n",
        "for class_label in num_classes:\n",
        "  videos = os.listdir(os.path.join(dataset_path, class_label))\n",
        "\n",
        "  for video in videos:\n",
        "    video_path = os.path.join(dataset_path, class_label, video)\n",
        "    frames = cv2.VideoCapture(video_path)\n",
        "\n",
        "    total_frames = int(frames.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    count_frames.append(total_frames)\n",
        "\n",
        "max_seq_len = np.max(count_frames)\n",
        "num_sampels = len(count_frames)"
      ],
      "metadata": {
        "id": "Fi0jHYiYb-uF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_video(path, resize):\n",
        "    import cv2\n",
        "\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    frames = []\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            frames.append(frame)\n",
        "\n",
        "    finally:\n",
        "        cap.release()\n",
        "\n",
        "    return frames, num_frames"
      ],
      "metadata": {
        "id": "p2ajInzxoO3m"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preparing_data():\n",
        "\n",
        "  labels = []\n",
        "  frames_dataset = []\n",
        "\n",
        "  num_classes = os.listdir(dataset_path)\n",
        "  frame_masks = np.zeros(shape=(num_sampels, max_seq_len), dtype=\"bool\")\n",
        "  video_count = 0\n",
        "\n",
        "  for class_label in num_classes:\n",
        "    videos = os.listdir(os.path.join(dataset_path, class_label))\n",
        "\n",
        "    for video in videos:\n",
        "      video_path = os.path.join(dataset_path, class_label, video)\n",
        "      frames, num_frames = load_video(video_path, (frame_height, frame_width))\n",
        "\n",
        "      padded_frames = np.zeros(shape=(max_seq_len, frame_height, frame_width, 3), dtype=\"float32\")\n",
        "      current_video_seq_len = min(max_seq_len, num_frames)\n",
        "\n",
        "      # Padding video frames\n",
        "      for i, frame in enumerate(np.array(frames)):\n",
        "          padded_frames[i, :] = frame / 255.\n",
        "\n",
        "      frames_dataset.append(padded_frames)\n",
        "      frame_masks[video_count, :current_video_seq_len] = 1\n",
        "\n",
        "      video_count+=1\n",
        "\n",
        "      # Create labels\n",
        "      if class_label == \"1\" : \n",
        "        labels.append(1) \n",
        "      else: \n",
        "        labels.append(0)\n",
        "\n",
        "  # Convert to np.array\n",
        "  frames_dataset = np.array(frames_dataset)\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  # Reshape labels\n",
        "  labels = labels[..., np.newaxis]\n",
        "\n",
        "  return [frames_dataset, frame_masks], labels"
      ],
      "metadata": {
        "id": "Z0uK2x4Aps1M"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call data preparing function\n",
        "\n",
        "X, Y = preparing_data()"
      ],
      "metadata": {
        "id": "sEo6LfRQyPdY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splite data\n",
        "\n",
        "X_train, X_val, mask_train, mask_val, Y_train, Y_val = train_test_split(X[0], X[1], Y, test_size = 0.2)\n",
        "X_train.shape, Y_train.shape, mask_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy52XnnqLRam",
        "outputId": "c707f5f0-1ca3-4171-b4c6-923b9d2000d8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17, 300, 112, 112, 3), (17, 1), (17, 300))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot\n",
        "\n",
        "# for frame in X_train[8]:\n",
        "#     plt.subplot(2, 2, 1)\n",
        "#     plt.imshow(frame[:, :, :], cmap=\"gray\")\n",
        "#     plt.show()"
      ],
      "metadata": {
        "id": "frAaizT5yjgT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcbBodgAoTL9"
      },
      "source": [
        "### Define Models, Compile and fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pok2XzZZpokl"
      },
      "source": [
        "01- RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mgmqYXNpUDjZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3393177-a6a5-4007-dd23-95fcd46f7271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 39s 6s/step - loss: 1.0135 - accuracy: 0.4706 - val_loss: 0.6793 - val_accuracy: 0.6000\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 36s 6s/step - loss: 0.6769 - accuracy: 0.4706 - val_loss: 0.6972 - val_accuracy: 0.4000\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 35s 6s/step - loss: 0.6543 - accuracy: 0.6471 - val_loss: 0.7437 - val_accuracy: 0.4000\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 35s 6s/step - loss: 0.6308 - accuracy: 0.6471 - val_loss: 0.7751 - val_accuracy: 0.4000\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 35s 6s/step - loss: 0.5843 - accuracy: 0.6471 - val_loss: 0.7298 - val_accuracy: 0.4000\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 35s 6s/step - loss: 0.5890 - accuracy: 0.7059 - val_loss: 0.7213 - val_accuracy: 0.2000\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 34s 6s/step - loss: 0.5023 - accuracy: 0.7647 - val_loss: 0.6472 - val_accuracy: 0.8000\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 37s 6s/step - loss: 0.4248 - accuracy: 1.0000 - val_loss: 0.7548 - val_accuracy: 0.6000\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 36s 6s/step - loss: 0.3375 - accuracy: 0.9412 - val_loss: 0.6545 - val_accuracy: 0.6000\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 35s 6s/step - loss: 0.2419 - accuracy: 1.0000 - val_loss: 0.8214 - val_accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f212804ae50>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "rnn_model = RNN_model(max_seq_len)\n",
        "\n",
        "rnn_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "rnn_model.fit([X_train, mask_train], Y_train, validation_data=[[X_val, mask_val], Y_val], batch_size=3, epochs=epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model.save_weights('/content/drive/MyDrive/video_classification_rnn/weights/rnn_model.h5')"
      ],
      "metadata": {
        "id": "64N1PdCV-BS-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MO5q5SHQS1Mj"
      },
      "outputs": [],
      "source": [
        "rnn_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "Ik08molDZysw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preparing_data(video_path):\n",
        "\n",
        "  labels = []\n",
        "  frames_dataset = []\n",
        "\n",
        "  frames, num_frames = load_video(video_path, (frame_height, frame_width))\n",
        "\n",
        "  frame_masks = np.zeros(shape=(1, num_frames), dtype=\"bool\")\n",
        "\n",
        "  # Reading video frames\n",
        "  frames = np.array(frames).astype(\"float32\") / 255.\n",
        "  frames = frames[np.newaxis, ...]\n",
        "  frame_masks[0, :] = 1\n",
        "\n",
        "  return frames, frame_masks, num_frames\n",
        "\n"
      ],
      "metadata": {
        "id": "6GokiFPz-iNB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_frames, input_masks, num_frames = preparing_data(\"/content/drive/MyDrive/dataset/joon_del/1/009.mp4\")\n",
        "input_frames.shape, input_masks.shape, num_frames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lP0dnJEGB7W-",
        "outputId": "19251fb6-9b6c-4586-de5b-b671d8e00f60"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1, 90, 112, 112, 3), (1, 90), 90)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = [\"حالت معمولی\", \"الهی صد هزار مرتبه شکر\"]\n",
        "\n",
        "model = RNN_model(num_frames)\n",
        "model.load_weights(\"/content/drive/MyDrive/video_classification_rnn/weights/rnn_model.h5\")\n",
        "pred = model.predict([input_frames, input_masks])\n",
        "\n",
        "predicted_class = np.argmax(pred)\n",
        "label = class_name[predicted_class]\n",
        "label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Jv4EzpNdBVsT",
        "outputId": "141bc611-7fa5-486a-d593-5d670edce08c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'الهی صد هزار مرتبه شکر'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "color = (255, 255, 0)\n",
        "video = cv2.VideoCapture(\"/content/drive/MyDrive/dataset/joon_del/1/009.mp4\")\n",
        "\n",
        "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "print(height, width)\n",
        "\n",
        "video_writer = cv2.VideoWriter('/content/drive/MyDrive/video_classification_rnn/out_put.avi', cv2.VideoWriter_fourcc(*'MJPG'), 10, (width, height), 0)\n",
        "\n",
        "while True:\n",
        "    ret, frame = video.read()\n",
        "    \n",
        "    if ret == True:\n",
        "      cv2.putText(frame, label, (width // 12, height // 12), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 1,\n",
        "                  cv2.LINE_AA)\n",
        "      \n",
        "      # cv2.imshow('color', frame_blur)\n",
        "      video_writer.write(frame)\n",
        "\n",
        "      plt.subplot(2, 2, 1)\n",
        "      plt.imshow(frame[:, :, :], cmap=\"gray\")\n",
        "      plt.show()\n",
        "        \n",
        "    else:\n",
        "      break\n",
        "\n",
        "video.release()\n",
        "video_writer.release()"
      ],
      "metadata": {
        "id": "bX2c5rO6cWAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/video_classification_rnn/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6IYkc4MvWnr",
        "outputId": "7f17aa7a-b643-4663-9a91-e7421156343e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/video_classification_rnn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 inference.py --input_path /content/drive/MyDrive/dataset/1/015.mp4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqAxg97nuTE2",
        "outputId": "4edf1451-d583-446e-9237-367167acd9ae"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-23 10:02:04.852772: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2022-04-23 10:02:05.500628: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 983851008 exceeds 10% of free system memory.\n",
            "2022-04-23 10:02:05.861094: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 5247205376 exceeds 10% of free system memory.\n",
            "tcmalloc: large alloc 5247205376 bytes == 0x55723c942000 @  0x7f23bdc28b6b 0x7f23bdc48379 0x7f237bf24257 0x7f236a3ae30f 0x7f236a44ad2b 0x7f236a25ed97 0x7f236a25f600 0x7f236a25f708 0x7f237516cc3b 0x7f236a5f1228 0x7f236a580843 0x7f236a581918 0x7f236ffb7ce1 0x7f236ffb49a3 0x7f236aca98d5 0x7f23bd9fb6db 0x7f23bcb3061f\n",
            "tcmalloc: large alloc 8854691840 bytes == 0x557375d62000 @  0x7f23bdc461e7 0x7f23721b3f3f 0x7f2374cb6eca 0x7f2375114464 0x7f237516445e 0x7f23751656f7 0x7f23751666fa 0x7f23751684ee 0x7f237516c842 0x7f237516cd2f 0x7f236a5f1228 0x7f236a580843 0x7f236a581918 0x7f236ffb7ce1 0x7f236ffb49a3 0x7f236aca98d5 0x7f23bd9fb6db 0x7f23bcb3061f\n",
            "2022-04-23 10:02:14.289618: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1311801344 exceeds 10% of free system memory.\n",
            "حالت معمولی\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inGdAnOnptWZ"
      },
      "source": [
        "#### 02- GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "x_XK3m1EpNGZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15bf8acd-9a71-400d-ee59-21cf8a6287c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 11s 681ms/step - loss: 1.5129 - accuracy: 0.4706 - val_loss: 1.2461 - val_accuracy: 0.4000\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 1s 239ms/step - loss: 0.8497 - accuracy: 0.5294 - val_loss: 0.7232 - val_accuracy: 0.4000\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 1s 238ms/step - loss: 0.7267 - accuracy: 0.4706 - val_loss: 0.6733 - val_accuracy: 0.6000\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 0.7368 - accuracy: 0.4706 - val_loss: 0.6731 - val_accuracy: 0.6000\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 0.7043 - accuracy: 0.4706 - val_loss: 0.6966 - val_accuracy: 0.4000\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 0.6972 - accuracy: 0.5294 - val_loss: 0.7398 - val_accuracy: 0.4000\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 1s 207ms/step - loss: 0.7026 - accuracy: 0.5294 - val_loss: 0.7374 - val_accuracy: 0.4000\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 0.7001 - accuracy: 0.5294 - val_loss: 0.7315 - val_accuracy: 0.4000\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 0.7096 - accuracy: 0.5294 - val_loss: 0.6932 - val_accuracy: 0.4000\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 0.6960 - accuracy: 0.5294 - val_loss: 0.6875 - val_accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f09b432b5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "gru_model = GRU_model(max_seq_len, frame_height, frame_width)\n",
        "\n",
        "gru_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "gru_model.fit([X_train, mask_train], Y_train, validation_data=[[X_val, mask_val], Y_val], batch_size=3, epochs=epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unkANfe_pNNh"
      },
      "outputs": [],
      "source": [
        "gru_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model.save_weights('/content/drive/MyDrive/video_classification_rnn/weights/gru_model.h5')"
      ],
      "metadata": {
        "id": "nhHFO_GZgQXd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT28bl7Npw_H"
      },
      "source": [
        "#### 03- LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OPvqrAWWpZD5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08638b5d-6bba-4fc8-c444-54741a986b16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 11s 698ms/step - loss: 2.2031 - accuracy: 0.4118 - val_loss: 1.4250 - val_accuracy: 0.6000\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 1.5117 - accuracy: 0.4706 - val_loss: 0.8409 - val_accuracy: 0.6000\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 0.9197 - accuracy: 0.3529 - val_loss: 0.7244 - val_accuracy: 0.4000\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 0.6962 - accuracy: 0.5294 - val_loss: 0.8428 - val_accuracy: 0.4000\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 1s 221ms/step - loss: 0.7536 - accuracy: 0.5294 - val_loss: 0.8428 - val_accuracy: 0.4000\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 0.7327 - accuracy: 0.5294 - val_loss: 0.7536 - val_accuracy: 0.4000\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 0.6936 - accuracy: 0.5294 - val_loss: 0.7159 - val_accuracy: 0.4000\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 0.6995 - accuracy: 0.4706 - val_loss: 0.6857 - val_accuracy: 0.6000\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 0.7012 - accuracy: 0.4706 - val_loss: 0.6896 - val_accuracy: 0.6000\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 1s 221ms/step - loss: 0.7003 - accuracy: 0.3529 - val_loss: 0.7000 - val_accuracy: 0.4000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f09d5d37990>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "lstm_model = LSTM_model(max_seq_len, frame_height, frame_width)\n",
        "\n",
        "lstm_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "lstm_model.fit([X_train, mask_train], Y_train, validation_data=[[X_val, mask_val], Y_val], batch_size=3, epochs=epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e38a73_pZPt"
      },
      "outputs": [],
      "source": [
        "lstm_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.save_weights('/content/drive/MyDrive/video_classification_rnn/weights/lstm_model.h5')"
      ],
      "metadata": {
        "id": "PqluU0zygb6Z"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31qYfPf9pi0o"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QAztDnpRPVoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "https://machinelearningmastery.com/use-different-batch-sizes-training-predicting-python-keras/\n",
        "https://keras.io/api/layers/recurrent_layers/time_distributed/#:~:text=TimeDistributed(layer%2C%20**kwargs),to%20be%20the%20temporal%20dimension.\n",
        "ffmpeg\n",
        "https://keras.io/examples/vision/video_classification/"
      ],
      "metadata": {
        "id": "7zkPFcxqsjFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -i /content/drive/MyDrive/dataset/0117.mp4 -ss 00:00:00 -t 00:00:08 -async 1 /content/drive/MyDrive/dataset/11.mp4"
      ],
      "metadata": {
        "id": "5aAmdvJFR3FY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "09- Video_Classification_CRNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}