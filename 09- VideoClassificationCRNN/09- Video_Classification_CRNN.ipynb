{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTdsiHXD79J6"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "%cd /content/drive/MyDrive/video_classification_rnn\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, SimpleRNN, GRU, LSTM, Dense, Flatten, TimeDistributed\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from models import RNN_model, GRU_model, LSTM_model\n",
        "from load_video import load_video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1EHFf5uq912f"
      },
      "outputs": [],
      "source": [
        "# Parameters setting\n",
        "\n",
        "frame_width = 112\n",
        "frame_height = 112\n",
        "\n",
        "batch_size = 1\n",
        "epochs = 10\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/dataset/joon_del\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "nRBVqvMwk8JH"
      },
      "outputs": [],
      "source": [
        "# Create directories\n",
        "\n",
        "if not os.path.exists(\"weights\"):\n",
        "    os.makedirs(\"weights\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNRiIBDroa3M"
      },
      "source": [
        "### Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Fi0jHYiYb-uF"
      },
      "outputs": [],
      "source": [
        "# Count maximum number of frames in all videos\n",
        "\n",
        "num_classes = os.listdir(dataset_path)\n",
        "count_frames = []\n",
        "\n",
        "for class_label in num_classes:\n",
        "  videos = os.listdir(os.path.join(dataset_path, class_label))\n",
        "\n",
        "  for video in videos:\n",
        "    video_path = os.path.join(dataset_path, class_label, video)\n",
        "    frames = cv2.VideoCapture(video_path)\n",
        "\n",
        "    total_frames = int(frames.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    count_frames.append(total_frames)\n",
        "\n",
        "max_seq_len = np.max(count_frames)\n",
        "num_sampels = len(count_frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Z0uK2x4Aps1M"
      },
      "outputs": [],
      "source": [
        "def preparing_data():\n",
        "\n",
        "  labels = []\n",
        "  frames_dataset = []\n",
        "\n",
        "  num_classes = os.listdir(dataset_path)\n",
        "  frame_masks = np.zeros(shape=(num_sampels, max_seq_len), dtype=\"bool\")\n",
        "  video_count = 0\n",
        "\n",
        "  for class_label in num_classes:\n",
        "    videos = os.listdir(os.path.join(dataset_path, class_label))\n",
        "\n",
        "    for video in videos:\n",
        "      video_path = os.path.join(dataset_path, class_label, video)\n",
        "      frames, num_frames = load_video(video_path, (frame_height, frame_width))\n",
        "\n",
        "      padded_frames = np.zeros(shape=(max_seq_len, frame_height, frame_width, 3), dtype=\"float32\")\n",
        "      current_video_seq_len = min(max_seq_len, num_frames)\n",
        "\n",
        "      # Normalize video frames\n",
        "      for i, frame in enumerate(np.array(frames)):\n",
        "          padded_frames[i, :] = frame / 255.\n",
        "\n",
        "      frames_dataset.append(padded_frames)\n",
        "      frame_masks[video_count, :current_video_seq_len] = 1\n",
        "\n",
        "      video_count+=1\n",
        "\n",
        "      # Create labels\n",
        "      if class_label == \"1\" : \n",
        "        labels.append(1) \n",
        "      else: \n",
        "        labels.append(0)\n",
        "\n",
        "  # Convert to np.array\n",
        "  frames_dataset = np.array(frames_dataset)\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  # Reshape labels\n",
        "  labels = labels[..., np.newaxis]\n",
        "\n",
        "  return [frames_dataset, frame_masks], labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "sEo6LfRQyPdY"
      },
      "outputs": [],
      "source": [
        "# Call data preparing function\n",
        "\n",
        "X, Y = preparing_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy52XnnqLRam",
        "outputId": "c707f5f0-1ca3-4171-b4c6-923b9d2000d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((17, 300, 112, 112, 3), (17, 1), (17, 300))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Splite data\n",
        "\n",
        "X_train, X_val, mask_train, mask_val, Y_train, Y_val = train_test_split(X[0], X[1], Y, test_size = 0.2)\n",
        "X_train.shape, Y_train.shape, mask_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcbBodgAoTL9"
      },
      "source": [
        "### Define Models, Compile and fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pok2XzZZpokl"
      },
      "source": [
        "01- RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgmqYXNpUDjZ",
        "outputId": "f3393177-a6a5-4007-dd23-95fcd46f7271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 39s 6s/step - loss: 1.0135 - accuracy: 0.4706 - val_loss: 0.6793 - val_accuracy: 0.6000\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 36s 6s/step - loss: 0.6769 - accuracy: 0.4706 - val_loss: 0.6972 - val_accuracy: 0.4000\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 35s 6s/step - loss: 0.6543 - accuracy: 0.6471 - val_loss: 0.7437 - val_accuracy: 0.4000\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 35s 6s/step - loss: 0.6308 - accuracy: 0.6471 - val_loss: 0.7751 - val_accuracy: 0.4000\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 35s 6s/step - loss: 0.5843 - accuracy: 0.6471 - val_loss: 0.7298 - val_accuracy: 0.4000\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 35s 6s/step - loss: 0.5890 - accuracy: 0.7059 - val_loss: 0.7213 - val_accuracy: 0.2000\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 34s 6s/step - loss: 0.5023 - accuracy: 0.7647 - val_loss: 0.6472 - val_accuracy: 0.8000\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 37s 6s/step - loss: 0.4248 - accuracy: 1.0000 - val_loss: 0.7548 - val_accuracy: 0.6000\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 36s 6s/step - loss: 0.3375 - accuracy: 0.9412 - val_loss: 0.6545 - val_accuracy: 0.6000\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 35s 6s/step - loss: 0.2419 - accuracy: 1.0000 - val_loss: 0.8214 - val_accuracy: 0.6000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f212804ae50>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnn_model = RNN_model(max_seq_len)\n",
        "\n",
        "rnn_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "rnn_model.fit([X_train, mask_train], Y_train, validation_data=[[X_val, mask_val], Y_val], batch_size=3, epochs=epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "64N1PdCV-BS-"
      },
      "outputs": [],
      "source": [
        "rnn_model.save_weights('/content/drive/MyDrive/video_classification_rnn/weights/rnn_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MO5q5SHQS1Mj"
      },
      "outputs": [],
      "source": [
        "rnn_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inGdAnOnptWZ"
      },
      "source": [
        "#### 02- GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_XK3m1EpNGZ",
        "outputId": "15bf8acd-9a71-400d-ee59-21cf8a6287c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 11s 681ms/step - loss: 1.5129 - accuracy: 0.4706 - val_loss: 1.2461 - val_accuracy: 0.4000\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 1s 239ms/step - loss: 0.8497 - accuracy: 0.5294 - val_loss: 0.7232 - val_accuracy: 0.4000\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 1s 238ms/step - loss: 0.7267 - accuracy: 0.4706 - val_loss: 0.6733 - val_accuracy: 0.6000\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 0.7368 - accuracy: 0.4706 - val_loss: 0.6731 - val_accuracy: 0.6000\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 0.7043 - accuracy: 0.4706 - val_loss: 0.6966 - val_accuracy: 0.4000\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 0.6972 - accuracy: 0.5294 - val_loss: 0.7398 - val_accuracy: 0.4000\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 1s 207ms/step - loss: 0.7026 - accuracy: 0.5294 - val_loss: 0.7374 - val_accuracy: 0.4000\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 0.7001 - accuracy: 0.5294 - val_loss: 0.7315 - val_accuracy: 0.4000\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 0.7096 - accuracy: 0.5294 - val_loss: 0.6932 - val_accuracy: 0.4000\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 0.6960 - accuracy: 0.5294 - val_loss: 0.6875 - val_accuracy: 0.6000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f09b432b5d0>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gru_model = GRU_model(max_seq_len, frame_height, frame_width)\n",
        "\n",
        "gru_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "gru_model.fit([X_train, mask_train], Y_train, validation_data=[[X_val, mask_val], Y_val], batch_size=3, epochs=epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unkANfe_pNNh"
      },
      "outputs": [],
      "source": [
        "gru_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nhHFO_GZgQXd"
      },
      "outputs": [],
      "source": [
        "gru_model.save_weights('/content/drive/MyDrive/video_classification_rnn/weights/gru_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT28bl7Npw_H"
      },
      "source": [
        "#### 03- LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPvqrAWWpZD5",
        "outputId": "08638b5d-6bba-4fc8-c444-54741a986b16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 11s 698ms/step - loss: 2.2031 - accuracy: 0.4118 - val_loss: 1.4250 - val_accuracy: 0.6000\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 1.5117 - accuracy: 0.4706 - val_loss: 0.8409 - val_accuracy: 0.6000\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 0.9197 - accuracy: 0.3529 - val_loss: 0.7244 - val_accuracy: 0.4000\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 0.6962 - accuracy: 0.5294 - val_loss: 0.8428 - val_accuracy: 0.4000\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 1s 221ms/step - loss: 0.7536 - accuracy: 0.5294 - val_loss: 0.8428 - val_accuracy: 0.4000\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 0.7327 - accuracy: 0.5294 - val_loss: 0.7536 - val_accuracy: 0.4000\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 0.6936 - accuracy: 0.5294 - val_loss: 0.7159 - val_accuracy: 0.4000\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 0.6995 - accuracy: 0.4706 - val_loss: 0.6857 - val_accuracy: 0.6000\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 0.7012 - accuracy: 0.4706 - val_loss: 0.6896 - val_accuracy: 0.6000\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 1s 221ms/step - loss: 0.7003 - accuracy: 0.3529 - val_loss: 0.7000 - val_accuracy: 0.4000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f09d5d37990>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lstm_model = LSTM_model(max_seq_len, frame_height, frame_width)\n",
        "\n",
        "lstm_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "lstm_model.fit([X_train, mask_train], Y_train, validation_data=[[X_val, mask_val], Y_val], batch_size=3, epochs=epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e38a73_pZPt"
      },
      "outputs": [],
      "source": [
        "lstm_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PqluU0zygb6Z"
      },
      "outputs": [],
      "source": [
        "lstm_model.save_weights('/content/drive/MyDrive/video_classification_rnn/weights/lstm_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik08molDZysw"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6GokiFPz-iNB"
      },
      "outputs": [],
      "source": [
        "def preparing_data(video_path):\n",
        "\n",
        "  labels = []\n",
        "  frames_dataset = []\n",
        "\n",
        "  frames, num_frames = load_video(video_path, (frame_height, frame_width))\n",
        "\n",
        "  frames_masks = np.zeros(shape=(1, num_frames), dtype=\"bool\")\n",
        "\n",
        "  # Normalize video frames\n",
        "  frames = np.array(frames).astype(\"float32\") / 255.\n",
        "  frames = frames[np.newaxis, ...]\n",
        "  frames_masks[0, :] = 1\n",
        "\n",
        "  return frames, frames_masks, num_frames\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lP0dnJEGB7W-",
        "outputId": "19251fb6-9b6c-4586-de5b-b671d8e00f60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1, 90, 112, 112, 3), (1, 90), 90)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_frames, input_masks, num_frames = preparing_data(\"/content/drive/MyDrive/dataset/joon_del/1/009.mp4\")\n",
        "input_frames.shape, input_masks.shape, num_frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Jv4EzpNdBVsT",
        "outputId": "141bc611-7fa5-486a-d593-5d670edce08c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'الهی صد هزار مرتبه شکر'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_name = [\"حالت معمولی\", \"الهی صد هزار مرتبه شکر\"]\n",
        "\n",
        "model = RNN_model(num_frames)\n",
        "model.load_weights(\"/content/drive/MyDrive/video_classification_rnn/weights/rnn_model.h5\")\n",
        "pred = model.predict([input_frames, input_masks])\n",
        "\n",
        "predicted_class = np.argmax(pred)\n",
        "label = class_name[predicted_class]\n",
        "label"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "09- Video_Classification_CRNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
